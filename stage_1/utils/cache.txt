# class SordiAiDataset(Dataset):
#    DIRECTORY = (
#        "/Users/sebastian/Documents/Projects/sordi_ai/src/data/SORDI_2022_Single_Assets"
#    )
#    IMG_EXTENSIONS = (
#        ".jpg",
#        ".jpeg",
#        ".png",
#        ".ppm",
#        ".bmp",
#        ".pgm",
#        ".tif",
#        ".tiff",
#        ".webp",
#    )
#
#    def __init__(
#        self,
#        root_path: str,
#        data_path: str = "SORDI_2022_Single_Assets",
#        transforms=None,
#        flag="train",
#    ) -> None:
#        super().__init__()
#        self.root_path = root_path
#        self.data_path = data_path
#        self.transforms = transforms
#        self.flag = flag
#
#        self._set_directory()
#        self.samples = self._make_dataset()
#
#
#    def _set_directory(self) -> None:
#        self.DIRECTORY = os.path.join(self.root_path, self.data_path)
#
#
#    def _make_dataset(self) -> List[Tuple[str, str]]:
#        instances = []
#        for directory in os.listdir(self.DIRECTORY):
#            if directory.startswith(".") or directory.endswith("json"):
#                continue
#            directory = os.fsdecode(directory)
#            # images, labels
#            images_path = os.path.join(self.DIRECTORY, directory, "images")
#            labels_path = os.path.join(self.DIRECTORY, directory, "labels/json")
#
#            images_paths = sorted(os.listdir(images_path))
#            labels_paths = sorted(os.listdir(labels_path))
#
#            for image, label in zip(images_paths, labels_paths):
#                if image.startswith(".") or label.startswith("."):
#                    continue
#                image = os.path.join(images_path, image)
#                label = os.path.join(labels_path, label)
#                instances.append((image, label))
#        return instances
#
#    def get_raw_image(self, index: int) -> torch.Tensor:
#        path_image, _ = self.samples[index]
#        return read_image(path_image)
#
#    def image_loader(self, path: str) -> Image.Image:
#        with open(path, "rb") as f:
#            img = Image.open(f)
#            return img.convert("RGB")
#
#    def json_loader(self, path: str) -> Dict:
#        with open(path, "rb") as json_file:
#            return json.load(json_file)
#
#    def _transform_label(self):
#        """
#        transforms box dimensions if necessary
#        transforms objects_ids
#        """
#        pass
#
#    def __len__(self) -> int:
#        return len(self.samples)
#
#    def __getitem__(self, index: int) -> Tuple:
#        # image after transform 3 ,720, 1280
#        path_image, path_label = self.samples[index]
#        image = self.image_loader(path_image)
#        label = self.json_loader(path_label)
#        image = self.transforms(image) if self.transforms else image
#        # print(image.shape)
#
#        return image, label[0]
#







        if flag == "test":
            shuffle_flag = False
            drop_last = True
            batch_size = args.batch_size
        elif flag == "eval":
            shuffle_flag = False
            drop_last = False
            batch_size = 1
        else:
            shuffle_flag = True
            drop_last = True
            batch_size = args.batch_size

        preprocess = self.weights.transforms()
        full_dataset = SordiAiDataset(
            root_path=args.root_path,
            data_path=args.data_path,
            transforms=preprocess,
            flag=flag,
        )
        data_set = train_test_split(full_dataset, flag) 
        data_loader = DataLoader(
            data_set,
            batch_size=batch_size,
            shuffle=shuffle_flag,
            num_workers=args.num_workers,
            drop_last=drop_last,
        )


        # transformed_targets = []
        # # sourcery skip: inline-immediately-returned-variable
        # for target in targets:  # i in range(len(targets)):
        #     # target = targets[i]
        #     x1, y1, x2, y2 = (
        #         target["Left"],
        #         target["Top"],
        #         target["Right"],
        #         target["Bottom"],
        #     )
        #     scale_width = self.width / 1280
        #     scale_height = self.height / 720

        #     x1 = int(x1 * scale_width)
        #     y1 = int(y1 * scale_height)
        #     x2 = int(x2 * scale_width)
        #     y2 = int(y2 * scale_height)
        #     target = {
        #         "boxes": torch.tensor([x1, y1, x2, y2]).unsqueeze(0),
        #         "labels": torch.tensor([CLASSES[str(target["ObjectClassName"])]]),
        #     }
        #    transformed_targets.append(target)
        # transformed_targets = {"boxes": [], "labels": []}
        # for target in targets:
        #    x1, y1, x2, y2 = (
        #        target["Left"],
        #        target["Top"],
        #        target["Right"],
        #        target["Bottom"],
        #    )
        #    scale_width = self.width / 1280
        #    scale_height = self.height / 720

        #    x1 = int(x1 * scale_width)
        #    y1 = int(y1 * scale_height)
        #    x2 = int(x2 * scale_width)
        #    y2 = int(y2 * scale_height)

        #    # transformed_targets["boxes"].append(torch.tensor([x1, y1, x2, y2]))
        #    # transformed_targets["labels"].append(
        #    #    torch.tensor([CLASSES[str(target["ObjectClassName"])]])
        #    # )
        #    transformed_targets["boxes"].append([x1, y1, x2, y2])
        #    transformed_targets["labels"].append(
        #        [CLASSES[str(target["ObjectClassName"])]]
        #    )
        # print(type(transformed_targets["boxes"]))
        # transformed_targets["boxes"] = torch.Tensor(transformed_targets["boxes"])
        # transformed_targets["labels"] = torch.Tensor(transformed_targets["labels"])