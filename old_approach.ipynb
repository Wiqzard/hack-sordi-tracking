{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4dbffd",
   "metadata": {},
   "source": [
    "# OLD APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddde6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6d7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a51f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PaddlePaddle/PaddleYOLO  # clone\n",
    "!cd PaddleYOLO\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49dcc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.训练（单卡/多卡），加 --eval 表示边训边评估，加 --amp 表示混合精度训练\n",
    "!cd PaddleYOLO && CUDA_VISIBLE_DEVICES=0 python tools/train.py -c PaddleDetection/PaddleYOLO/configs/custom/yolov8_m_500e_coco.yml --eval --amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!CUDA_VISIBLE_DEVICES=0 python tools/export_model.py -c configs/mot/bytetrack/detector/ppyoloe_crn_l_36e_640x640_mot17half.yml -o weights=https://paddledet.bj.bcebos.com/models/mot/ppyoloe_crn_l_36e_640x640_mot17half.pdparams\n",
    "%cd PaddleDetection\n",
    "!CUDA_VISIBLE_DEVICES=0 python tools/export_model.py -c /home/5qx9nf8a/team_workspace/PaddleDetection/configs/mot/bytetrack/detector/ppyoloe_plus_l_bytetrack.yml -o weights=/home/5qx9nf8a/team_workspace/PaddleDetection//tracking/model_final.pdparams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f04d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracking.tracking_counter import create_submission_dict, write_submission\n",
    "\n",
    "#submission_dict = create_submission_dict(scanned_racks=scanner.rack_tracks, mAP=96.3, fps=19.47)99.71\n",
    "submission_dict = create_submission_dict(scanned_racks=saved_racks, mAP=96.3, fps=0) \n",
    "\n",
    "write_submission(submission_dict=submission_dict, submission_path=\"temp/AcademicWeapons.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c82fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"data/Hackathon_Stage2/Evaluation_set/video/eval_video_1.mp4\"\n",
    "img = \"data/Hackathon_Stage2/Evaluation_set/dataset/images/109.jpg\"\n",
    "engine = \"runs/detect/train2/weights/best.engine\"\n",
    "data = \"data/trans_data/val/images\"\n",
    "import cv2\n",
    "im = cv2.imread(img)[None]\n",
    "print(im.shape)\n",
    "from ultralytics.yolo.v8.detect.predict import DetectionPredictor\n",
    "predictor = DetectionPredictor() #CustomPredictor()#\n",
    "predictor.setup_model(model=engine)\n",
    "predictor.imgsz = (3, 960, 960)\n",
    "predictor.args.mode = \"predict\"\n",
    "predictor.args.imgsz = 960\n",
    "predictor.args.save = False\n",
    "predictor.args.cache = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b22394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "with VideoSink(TARGET_VIDEO_PATH, 1, video_info) as sink:\n",
    "    detect_time, track_up_time, track_matcher, box_anno, scanner_up, scanner_anno, writer = 0,0,0,0,0,0,0\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(generator), total=video_info.total_frames):\n",
    "        \n",
    "        start = time()\n",
    "        results = predictor(source=frame)\n",
    "        end = time()\n",
    "        detect_time += end - start\n",
    "        \n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        if detections.xyxy.shape[0] != 0:\n",
    "            # tracking detections\n",
    "            start = time()\n",
    "            tracks = byte_tracker.update(\n",
    "                output_results=detections2boxes(detections=detections),\n",
    "                img_info=frame.shape,\n",
    "                img_size=frame.shape\n",
    "            )\n",
    "            end = time()\n",
    "            track_up_time += end - start\n",
    "            \n",
    "            start = time()\n",
    "            tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "            end = time()\n",
    "            track_matcher += end - start\n",
    "            \n",
    "            detections.tracker_id = np.array(tracker_id)\n",
    "\n",
    "            # filtering out detections without trackers\n",
    "            mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "            detections.filter(mask=mask, inplace=True)\n",
    "            detection_list.append(detections)\n",
    "            \n",
    "            # format custom labels\n",
    "            labels = [\n",
    "                f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "                for _, confidence, class_id, tracker_id\n",
    "                in detections\n",
    "            ]\n",
    "            \n",
    "            # annotatoe detection boxes\n",
    "            start = time()\n",
    "            #frame = box_annotator.annotate(\n",
    "            #    frame=frame, detections=detections, labels=labels\n",
    "            #)\n",
    "            end = time()\n",
    "            box_anno += end - start\n",
    "            \n",
    "            # update the scanner\n",
    "            start = time()\n",
    "            scanner.update(detections=detections)\n",
    "            end = time()\n",
    "            scanner_up += end - start\n",
    "            # draw the scanner\n",
    "            start = time()\n",
    "            #scanner_annotator.annotate(frame=frame, rack_scanner=scanner)\n",
    "            end = time()\n",
    "            scanner_anno += end - start\n",
    "            # add the annotated frame to video\n",
    "        start = time()\n",
    "        sink.write_frame(frame)\n",
    "        end = time()\n",
    "        writer += end - start\n",
    "print(round(detect_time, 3)*  1000)\n",
    "print(round(track_up_time, 3)* 1000)\n",
    "print(round(track_matcher, 3)* 1000)\n",
    "print(round(box_anno, 3)* 1000)\n",
    "print(round(scanner_up, 3)* 1000)\n",
    "print(round(scanner_anno, 3)* 1000)\n",
    "print(round(writer, 3)* 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
